<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="keywords" content="Ning Yu; 于宁; Computer Vision; Visual Security; Deep Generative Modeling; University of Maryland; UMD; Max Planck Institute for Informatics; MPI-INF">
<link rel="author" href="https://ningyu1991.github.io/">

<title>Ning Yu's Homepage</title>

<style>
@media screen and (max-device-width: 480px){
  body{
    -webkit-text-size-adjust: none;
  }
}
p { font-size : 16px; }
h1 { font-size : 34px; margin : 0; padding : 0; }
h2 { font-size : 20px; margin : 0; padding : 0; }
h3 { font-size : 18px; margin : 8; padding : 0; }
body { padding : 0; font-family : Arial; font-size : 16px; background-color : #fff; }
.title { width : 700px; margin : 20px auto; }
.container { width : 900px; margin : 20px auto; border-radius: 10px;  background-color : #fff; padding : 20px;  clear:both;}
#bio {
    padding-top : 30px;
}
#me { border : 0 solid black; margin-bottom : 50px; border-radius : 10px; }
#sidebar { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0;}
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
.publogo { width: 100 px; margin-right : 20px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 5px;}
.publication strong a { color : #0000A0; }
.publication .links a { margin-right : 20px; }
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
.external a { margin : 0 10px; }
.external a.first { margin : 0 10px 0 0; }
</style>

<script async="" src="./homepage_files/analytics.js"></script>
</head>

<body>
    <div class="title">
        <div id="sidebar"><img src="./homepage_files/me.jpg" vspace="50 px" width="270 px" id="me" itemprop="photo"></div>
        <div id="bio">

            <br>

            <h1>
                <span itemprop="name">Ning Yu <font size="5">于宁</font> </span>
            </h1>

            <br>

            <p style="line-height:23px;">
                Ph.D. Student
                <br>
                University of Maryland (UMD)
                <br>
                Max Planck Institute for Informatics (MPI-INF)
                <br>
                <br>
                ningyu at cs.umd.edu
                <br>
                ningyu at mpi-inf.mpg.de
                <br>
                <br>
            </p>
            <p class="external">
                <a href="https://scholar.google.com/citations?user=TaJND9YAAAAJ&hl=en" class="first" target="_blank" rel="nofollow">Google Scholar</a>|
                <a href="https://github.com/ningyu1991" target="_blank" rel="nofollow">GitHub</a>|
                <a href="https://www.linkedin.com/in/ning-yu-51b31087" target="_blank" rel="nofollow">LinkedIn</a>|
                <a href="https://twitter.com/realNingYu" target="_blank" rel="nofollow">Twitter</a>
                <br>
                <br>
                <a href="#sect-news" class="first">News</a>|
                <a href="#sect-publications">Publications</a>|
                <a href="#sect-patents">Patents</a>|
                <a href="#sect-awards">Awards</a>
                <a href="#sect-mentoring" class="first">Mentoring</a>|
                <a href="#sect-reviewing">Reviewing</a>|
                <a href="#sect-teaching">Teaching</a>
            </p>
        </div>
    </div>

    <div class="container">
        <p>
            <h2>About me</h2>
            <br>
            I am a Ph.D. student in Computer Science jointly affiliated with the University of Maryland and Max Planck Institute for Informatics, under the supervision of <a href="http://legacydirs.umiacs.umd.edu/~lsd/" target="_blank" rel="nofollow">Larry Davis</a> and <a href="https://cispa.saarland/group/fritz/" target="_blank" rel="nofollow">Mario Fritz</a>.
            <br>
            <br>
            My research aspirations lie in computer vision and visual security, with a focused lens at the bright side and dark side of deep generative models. I am passionate about recreating the visual world in a responsible manner against deep fake misuse.
            <br>
            <br>
            I interned at NVIDIA Research and at Adobe Research x2.
            <br>
            <br>
            My selected works include <a href="https://arxiv.org/pdf/2103.16748.pdf" target="_blank" rel="nofollow">Contrast and Attention GANs</a>, <a href="https://arxiv.org/pdf/2012.08726" target="_blank" rel="nofollow">Scalable GAN Fingerprints</a>, <a href="https://arxiv.org/pdf/2007.08457.pdf" target="_blank" rel="nofollow">Artificial GAN Fingerprints</a>, <a href="./projects/GANFingerprints.html" target="_blank" rel="nofollow">GAN Fingerprints</a>, <a href="./projects/InclusiveGAN.html" target="_blank" rel="nofollow">Inclusive GAN</a>, <a href="./projects/TextureMixer.html" target="_blank" rel="nofollow">Texture Mixer</a>, and <a href="./projects/DefectDetection.html" target="_blank" rel="nofollow">Defect Detection</a>.
            <br>
            <br>
            My research was featured in media press such as thejiangmen, QbitAI, and foodplus.
            <br>
            <br>
            I am a recipient of <a href="https://blog.twitch.tv/en/2021/01/07/introducing-our-2021-twitch-research-fellows/" target="_blank" rel="nofollow">Twitch (Amazon) Research Fellowship</a>, Microsoft Young Fellowship, <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/finalists" target="_blank" rel="nofollow">Qualcomm Innovation Fellowship Finalist x2</a>, and <a href="http://spie.org/about-spie/press-room/mi15-news" target="_blank" rel="nofollow">SPIE Best Student Paper Finalist</a>.
        </p>
    </div>

    <div class="container">
        <p id="sect-news">
            <h2>News</h2>
            <br>
            [09/2021] Our code for <a href="https://github.com/ningyu1991/ArtificialGANFingerprints" target="_blank" rel="nofollow">Artificial GAN Fingerprints</a> is released.
            <br>
            [08/2021] Our work on <a href="https://www.sciencedirect.com/science/article/abs/pii/S0308814621020008" target="_blank" rel="nofollow">CV for Food Nutrient Estimation</a> is accepted to Food Chemistry 2021.
            <br>
            [08/2021] Our code for <a href="https://github.com/SSAW14/BeyondtheSpectrum" target="_blank" rel="nofollow">Beyond the Spectrum</a> is released.
            <br>
            [07/2021] Our work on <a href="https://arxiv.org/pdf/2007.08457.pdf" target="_blank" rel="nofollow">Artificial GAN Fingerprints</a> is accepted to ICCV 2021 as <strong style="color: red;">Oral</strong>.
            <br>
            [07/2021] Our work on <a href="https://arxiv.org/pdf/2103.16748.pdf" target="_blank" rel="nofollow">Dual Contrastive Loss and Attention for GANs</a> is accepted to ICCV 2021.
            <br>
            [06/2021] Our code for <a href="https://github.com/a514514772/hijackgan" target="_blank" rel="nofollow">Hijack-GAN</a> is released.
            <br>
            [05/2021] Our work on <a href="https://www.sciencedirect.com/science/article/abs/pii/S0963996921003367" target="_blank" rel="nofollow">CV for Food Nutrient Prediction</a> is accepted to Food Research International 2021.
            <br>
            [04/2021] Our work on <a href="https://arxiv.org/pdf/2105.14376.pdf" target="_blank" rel="nofollow">Re-Synthesis for Deepfake Detection</a> is accepted to IJCAI 2021.
            <br>
            [03/2021] Our work on <a href="https://www.sciencedirect.com/science/article/abs/pii/S0889157521000570" target="_blank" rel="nofollow">AI for Food Nutrient Estimation</a> is accepted to Journal of Food Composition and Analysis 2021.
            <br>
            [02/2021] Our work on <a href="https://arxiv.org/pdf/2011.14107.pdf" target="_blank" rel="nofollow">Hijack-GAN</a> is accepted to CVPR 2021.
            <br>
            [01/2021] Our code for <a href="https://github.com/ningyu1991/InclusiveGAN" target="_blank" rel="nofollow">Inclusive GAN</a> is released.
            <br>
            [09/2020] Our code for <a href="https://github.com/ssfootball04/class-balanced-experts" target="_blank" rel="nofollow">Class Balanced Experts for Long-Tailed Recognition</a> is released.
            <br>
            [08/2020] Our work on <a href="https://arxiv.org/pdf/2004.03706.pdf" target="_blank" rel="nofollow">Class Balanced Experts for Long-Tailed Recognition</a> is accepted to GCPR 2020.
            <br>
            [08/2020] Our code for <a href="https://github.com/DingfanChen/GAN-Leaks" target="_blank" rel="nofollow">GAN-Leaks</a> is released.
            <br>
            [06/2020] Our work on <a href="https://arxiv.org/pdf/2004.03355.pdf" target="_blank" rel="nofollow">Inclusive GAN</a> is accepted to ECCV 2020.
            <br>
            [03/2020] Our work on <a href="https://arxiv.org/pdf/1909.03935.pdf" target="_blank" rel="nofollow">GAN-Leaks</a> is accepted to CCS 2020.
        </p>
    </div>

    <div class="container">
        <p id="sect-publications">
            <h2>Publications</h2>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_ArtificialGANFingerprints.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="https://arxiv.org/pdf/2007.08457.pdf" target="_blank" rel="nofollow">Artificial Fingerprinting for Generative Models: Rooting Deepfake Attribution in Training Data</a>
                            </strong>
                            <br>
                            <br>
                            <b>Ning Yu</b>*, Vladislav Skripniuk*, Sahar Abdelnabi, Mario Fritz
                            <br>
                            <br>
                            <em>ICCV 2021 <strong style="color: red;">Oral</strong></em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="https://arxiv.org/pdf/2007.08457.pdf" target="_blank" rel="nofollow">pdf</a>
                                <a href="https://github.com/ningyu1991/ArtificialGANFingerprints" target="_blank" rel="nofollow">code</a>
                                <a href="./homepage_files/poster_ArtificialGANFingerprints.pdf" target="_blank" rel="nofollow">poster</a>
                                <a href="https://www.youtube.com/watch?v=j8bcOHhu4Lg&t=12s" target="_blank" rel="nofollow">video</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_AttentionContrastGAN.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="https://arxiv.org/pdf/2103.16748.pdf" target="_blank" rel="nofollow">Dual Contrastive Loss and Attention for GANs</a>
                            </strong>
                            <br>
                            <br>
                            <b>Ning Yu</b>, Guilin Liu, Aysegul Dundar, Andrew Tao, Bryan Catanzaro, Larry Davis, Mario Fritz
                            <br>
                            <br>
                            <em>ICCV 2021</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="https://arxiv.org/pdf/2103.16748.pdf" target="_blank" rel="nofollow">pdf</a>
                                <a href="https://github.com/ningyu1991/AttentionDualContrastGAN" target="_blank" rel="nofollow">code</a>
                                <a href="./homepage_files/poster_AttentionDualContrastGAN.pdf" target="_blank" rel="nofollow">poster</a>
                                <a href="https://www.youtube.com/watch?v=hviCTQJzhd0" target="_blank" rel="nofollow">video</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_ScalableGANFingerprints.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="https://arxiv.org/pdf/2012.08726" target="_blank" rel="nofollow">Responsible Disclosure of Generative Models Using Scalable Fingerprinting</a>
                            </strong>
                            <br>
                            <br>
                            <b>Ning Yu</b>*, Vladislav Skripniuk*, Dingfan Chen, Larry Davis, Mario Fritz
                            <br>
                            <br>
                            <em>arXiv 2021</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="https://arxiv.org/pdf/2012.08726" target="_blank" rel="nofollow">pdf</a>
                                <a href="https://github.com/ningyu1991/ScalableGANFingerprints" target="_blank" rel="nofollow">code</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_VideoInpaintingDetection.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="https://arxiv.org/pdf/2101.11080.pdf" target="_blank" rel="nofollow">Deep Video Inpainting Detection</a>
                            </strong>
                            <br>
                            <br>
                            Peng Zhou, <b>Ning Yu</b>, Zuxuan Wu, Larry Davis, Abhinav Shrivastava, Ser-Nam Lim
                            <br>
                            <br>
                            <em>arXiv 2021</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="https://arxiv.org/pdf/2101.11080.pdf" target="_blank" rel="nofollow">pdf</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_ResynthesizerGANDetection.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="https://arxiv.org/pdf/2105.14376.pdf" target="_blank" rel="nofollow">Beyond the Spectrum: Detecting Deepfakes via Re-Synthesis</a>
                            </strong>
                            <br>
                            <br>
                            Yang He, <b>Ning Yu</b>, Margret Keuper, Mario Fritz
                            <br>
                            <br>
                            <em>IJCAI 2021</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="https://arxiv.org/pdf/2105.14376.pdf" target="_blank" rel="nofollow">pdf</a>
                                <a href="https://ssaw14.github.io/BeyondtheSpectrum/" target="_blank" rel="nofollow">project</a>
                                <a href="https://github.com/SSAW14/BeyondtheSpectrum" target="_blank" rel="nofollow">code</a>
                                <a href="https://www.youtube.com/watch?v=kQeREkzrrPM" target="_blank" rel="nofollow">video</a>
                                <a href="https://mp.weixin.qq.com/s/Vffg2wexqcEpJYDhXg__7g" target="_blank" rel="nofollow">press</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_HijackGAN.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="https://a514514772.github.io/hijackgan/" target="_blank" rel="nofollow">Hijack-GAN: Unintended-Use of Pretrained, Black-Box GANs</a>
                            </strong>
                            <br>
                            <br>
                            Hui-Po Wang, <b>Ning Yu</b>, Mario Fritz
                            <br>
                            <br>
                            <em>CVPR 2021</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="https://arxiv.org/pdf/2011.14107.pdf" target="_blank" rel="nofollow">pdf</a>
                                <a href="https://a514514772.github.io/hijackgan/" target="_blank" rel="nofollow">project</a>
                                <a href="https://github.com/a514514772/hijackgan" target="_blank" rel="nofollow">code</a>
                                <a href="https://a514514772.github.io/hijackgan/assets/poster.pdf" target="_blank" rel="nofollow">poster</a>
                                <a href="https://www.youtube.com/watch?v=M3rv4fqUoNQ" target="_blank" rel="nofollow">video</a>
                                <a href="https://mp.weixin.qq.com/s/Z7YGrGYxvV12AUt6sJUvJg" target="_blank" rel="nofollow">press</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_ChineseMarketFoodNutrientEstimation.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0308814621020008" target="_blank" rel="nofollow">Application of Deep Learning for Image-based Chinese Market Food Nutrients Estimation</a>
                            </strong>
                            <br>
                            <br>
                            Peihua Ma, Chun Pong Lau, <b>Ning Yu</b>, An Li, Jiping Sheng
                            <br>
                            <br>
                            <em>Food Chemistry 2021</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0308814621020008" target="_blank" rel="nofollow">pdf</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_ChineseFoodNutrientPrediction.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0963996921003367" target="_blank" rel="nofollow">Image-based Nutrient Estimation for Chinese Dishes Using Deep Learning</a>
                            </strong>
                            <br>
                            <br>
                            Peihua Ma, Chun Pong Lau, <b>Ning Yu</b>, An Li, Ping Liu, Qin Wang, Jiping Sheng
                            <br>
                            <br>
                            <em>Food Research International 2021</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0963996921003367" target="_blank" rel="nofollow">pdf</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_FoodNutrientPrediction.jpg" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0889157521000570" target="_blank" rel="nofollow">Application of Machine Learning for Predicting Label Nutrients Using USDA Global Branded Food Products Database (BFPD)</a>
                            </strong>
                            <br>
                            <br>
                            Peihua Ma, An Li, <b>Ning Yu</b>, Ying Li, Rahul Bahadur, Qin Wang, Jaspreet Ahuja
                            <br>
                            <br>
                            <em>Journal of Food Composition and Analysis 2021</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0889157521000570" target="_blank" rel="nofollow">pdf</a>
                                <a href="https://mp.weixin.qq.com/s/Q_Gq1R5pRuxQQGvvrYnn_Q" target="_blank" rel="nofollow">press</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_ClassBalancedExperts.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="https://arxiv.org/pdf/2004.03706.pdf" target="_blank" rel="nofollow">Long-Tailed Recognition Using Class-Balanced Experts</a>
                            </strong>
                            <br>
                            <br>
                            Saurabh Sharma, <b>Ning Yu</b>, Mario Fritz, Bernt Schiele
                            <br>
                            <br>
                            <em>GCPR 2020</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="https://arxiv.org/pdf/2004.03706.pdf" target="_blank" rel="nofollow">pdf</a>
                                <a href="https://github.com/ssfootball04/class-balanced-experts" target="_blank" rel="nofollow">code</a>
                                <a href="https://www.youtube.com/watch?v=1rxMDoIm6oM&feature=youtu.be&t=29m58s" target="_blank" rel="nofollow">video</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_GANLeaks.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="https://arxiv.org/pdf/1909.03935.pdf" target="_blank" rel="nofollow">GAN-Leaks: A Taxonomy of Membership Inference Attacks against GANs</a>
                            </strong>
                            <br>
                            <br>
                            Dingfan Chen, <b>Ning Yu</b>, Yang Zhang, Mario Fritz
                            <br>
                            <br>
                            <em>CCS 2020</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="https://arxiv.org/pdf/1909.03935.pdf" target="_blank" rel="nofollow">pdf</a>
                                <a href="https://github.com/DingfanChen/GAN-Leaks" target="_blank" rel="nofollow">code</a>
                                <a href="./homepage_files/poster_GANLeaks.pdf" target="_blank" rel="nofollow">poster</a>
                                <a href="https://www.youtube.com/watch?v=UkOe_sGRYec" target="_blank" rel="nofollow">video (short)</a>
                                <a href="https://www.youtube.com/watch?v=APnsV8AFXZQ" target="_blank" rel="nofollow">video (full)</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_InclusiveGAN.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="./projects/InclusiveGAN.html" target="_blank" rel="nofollow">Inclusive GAN: Improving Data and Minority Coverage in Generative Models</a>
                            </strong>
                            <br>
                            <br>
                            <b>Ning Yu</b>, Ke Li, Peng Zhou, Jitendra Malik, Larry Davis, Mario Fritz
                            <br>
                            <br>
                            <em>ECCV 2020</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="https://arxiv.org/pdf/2004.03355.pdf" target="_blank" rel="nofollow">pdf</a>
                                <a href="./projects/InclusiveGAN.html" target="_blank" rel="nofollow">project</a>
                                <a href="https://github.com/ningyu1991/InclusiveGAN" target="_blank" rel="nofollow">code</a>
                                <a href="https://www.youtube.com/watch?v=JbHWuLsn_zg" target="_blank" rel="nofollow">video (short)</a>
                                <a href="https://www.youtube.com/watch?v=oCb4cpsQ7do" target="_blank" rel="nofollow">video (full)</a>
                                <a href="https://mp.weixin.qq.com/s/6CCWQY8d0NoHEuMqWEp2dw" target="_blank" rel="nofollow">press</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_GANFingerprints.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="./projects/GANFingerprints.html" target="_blank" rel="nofollow">Attributing Fake Images to GANs: Learning and Analyzing GAN Fingerprints</a>
                            </strong>
                            <br>
                            <br>
                            <b>Ning Yu</b>, Larry Davis, Mario Fritz
                            <br>
                            <br>
                            <em>ICCV 2019</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="https://arxiv.org/pdf/1811.08180.pdf" target="_blank" rel="nofollow">pdf</a>
                                <a href="./projects/GANFingerprints.html" target="_blank" rel="nofollow">project</a>
                                <a href="https://github.com/ningyu1991/GANFingerprints" target="_blank" rel="nofollow">code</a>
                                <a href="./homepage_files/poster_GANFingerprints.pdf" target="_blank" rel="nofollow">poster</a>
                                <a href="https://mp.weixin.qq.com/s/se1ZyR_gfzliWB5X72OZ1Q" target="_blank" rel="nofollow">press</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_TextureMixer.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="./projects/TextureMixer.html" target="_blank" rel="nofollow">Texture Mixer: A Network for Controllable Synthesis and Interpolation of Texture</a>
                            </strong>
                            <br>
                            <br>
                            <b>Ning Yu</b>, Connelly Barnes, Eli Shechtman, Sohrab Amirghodsi, Michal Lukáč
                            <br>
                            <br>
                            <em>CVPR 2019</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="https://arxiv.org/pdf/1901.03447.pdf" target="_blank" rel="nofollow">pdf</a>
                                <a href="./projects/TextureMixer.html" target="_blank" rel="nofollow">project</a>
                                <a href="https://github.com/ningyu1991/TextureMixer" target="_blank" rel="nofollow">code</a>
                                <a href="./homepage_files/poster_TextureMixer.pdf" target="_blank" rel="nofollow">poster</a>
                                <a href="https://mp.weixin.qq.com/s/b_gIB_zpUCcf2a8ImKMXRA" target="_blank" rel="nofollow">press</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_DefectDetection.jpg" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="./projects/DefectDetection.html" target="_blank" rel="nofollow">Learning to Detect Multiple Photographic Defects</a>
                            </strong>
                            <br>
                            <br>
                            <b>Ning Yu</b>, Xiaohui Shen, Zhe Lin, Radomír Měch, Connelly Barnes
                            <br>
                            <br>
                            <em>WACV 2018</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="https://arxiv.org/pdf/1612.01635.pdf" target="_blank" rel="nofollow">pdf</a>
                                <a href="./homepage_files/supp_DefectDetection.pdf" target="_blank" rel="nofollow">supp</a>
                                <a href="./projects/DefectDetection.html" target="_blank" rel="nofollow">project</a>
                                <a href="https://github.com/ningyu1991/DefectDetection" target="_blank" rel="nofollow">code</a>
                                <a href="./homepage_files/poster_DefectDetection.pdf" target="_blank" rel="nofollow">poster</a>
                                <a href="./homepage_files/slides_DefectDetection.pptx" target="_blank" rel="nofollow">slides</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_SupervoxelMRFSeg.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="./projects/SupervoxelMRFSeg.html" target="_blank" rel="nofollow">Supervoxel-Based Hierarchical Markov Random Field Framework for Multi-Atlas Segmentation</a>
                            </strong>
                            <br>
                            <br>
                            <b>Ning Yu</b>, Hongzhi Wang, Paul Yushkevich
                            <br>
                            <br>
                            <em>MICCAI Workshop 2016</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="./homepage_files/paper_SupervoxelMRFSeg.pdf" target="_blank" rel="nofollow">pdf</a>
                                <a href="./projects/SupervoxelMRFSeg.html" target="_blank" rel="nofollow">project</a>
                                <a href="./homepage_files/slides_SupervoxelMRFSeg.pptx" target="_blank" rel="nofollow">slides</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_SuperpixelBreastTumorSeg.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="./projects/SuperpixelBreastTumorSeg.html" target="_blank" rel="nofollow">A Superpixel-Based Framework for Automatic Tumor Segmentation on Breast DCE-MRI</a>
                            </strong>
                            <br>
                            <br>
                            <b>Ning Yu</b>, Jia Wu, Susan Weinstein, Bilwaj Gaonkar, Brad Keller, Ahmed Ashraf, YunQing Jiang, Christos Davatzikos, Emily Conant, Despina Kontos
                            <br>
                            <br>
                            <em>SPIE Medical Imaging 2015 (oral, best student paper finalist)</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="./homepage_files/paper_SuperpixelBreastTumorSeg.pdf" target="_blank" rel="nofollow">pdf</a>
                                <a href="./projects/SuperpixelBreastTumorSeg.html" target="_blank" rel="nofollow">project</a>
                                <a href="./homepage_files/slides_SuperpixelBreastTumorSeg.pptx" target="_blank" rel="nofollow">slides</a>
                                <a href="http://spie.org/about-spie/press-room/mi15-news" target="_blank" rel="nofollow">press</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_QuantBreastTumorReg.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="./homepage_files/paper_QuantBreastTumorReg.pdf" target="_blank" rel="nofollow">Quantification of Tumor Changes during Neoadjuvant Chemotherapy with Longitudinal Breast DCE-MRI Registration</a>
                            </strong>
                            <br>
                            <br>
                            Jia Wu, Yangming Ou, Susan Weinstein, Emily Conant, <b>Ning Yu</b>, Vahid Hoshmand, Brad Keller, Ahmed Ashraf, Mark Rosen, Angela DeMichele, Christos Davatzikos,  Despina Kontos
                            <br>
                            <br>
                            <em>SPIE Medical Imaging 2015</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="./homepage_files/paper_QuantBreastTumorReg.pdf" target="_blank" rel="nofollow">pdf</a>
    、                        </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_BreastTumorPattern.jpg" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="./homepage_files/paper_BreastTumorPattern.pdf" target="_blank" rel="nofollow">Tumor Heterogeneity Patterns of DCE-MRI Parametric Response Maps May Augment Early Assessment of Neoadjuvant Chemotherapy: A Pilot Study of ACRIN 6657/I-SPY 1</a>
                            </strong>
                            <br>
                            <br>
                            Jia Wu, Susan Weinstein, Andrew Oustimov, Lauren Pantalone, <b>Ning Yu</b>, Yangming Ou, Mark Rosen, Angela DeMichele, Christos Davatzikos, Despina Kontos
                            <br>
                            <br>
                            <em>RSNA 2015</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="./homepage_files/paper_BreastTumorPattern.pdf" target="_blank" rel="nofollow">pdf</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_InvestigationBreatTumorReg.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="./homepage_files/paper_InvestigationBreatTumorReg.pdf" target="_blank" rel="nofollow">A Feasibility Study Investigating the Use of Quantitative Measures of Spatio-Temporal Tumor Heterogeneity Derived from 4D Breast DCE-MRI Registration as a Biomarker of Response to Neoadjuvant Chemotherapy</a>
                            </strong>
                            <br>
                            <br>
                            Jia Wu, Yangming Ou, Susan Weinstein, Emily Conant, <b>Ning Yu</b>, Vahid Hoshmand, Brad Keller, Ahmed Ashraf, Mark Rosen, Angela DeMichele, Christos Davatzikos,  Despina Kontos
                            <br>
                            <br>
                            <em>ISMRM Workshop 2014</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="./homepage_files/paper_InvestigationBreatTumorReg.pdf" target="_blank" rel="nofollow">pdf</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
            <div class="publication">
                <table><tbody>
                    <tr>
                        <td>
                            <img src="./homepage_files/logo_FeaturePointCorrespondencesTracking.png" class="publogo" width="200 px">
                        </td>
                        <td>
                            <strong>
                                <a href="./projects/FeaturePointCorrespondencesTracking.html" target="_blank" rel="nofollow">Robust Feature Points Correspondences for Visual Object Tracking</a>
                            </strong>
                            <br>
                            <br>
                            <b>Ning Yu</b>
                            <br>
                            <br>
                            <em>Undergraduate Thesis 2013</em>
                            <br>
                            <br>
                            <span class="links">
                                <a href="./homepage_files/paper_FeaturePointCorrespondencesTracking.pdf" target="_blank" rel="nofollow">pdf</a>
                                <a href="./projects/FeaturePointCorrespondencesTracking.html" target="_blank" rel="nofollow">project</a>
                                <a href="./homepage_files/slides_FeaturePointCorrespondencesTracking.pptx" target="_blank" rel="nofollow">slides</a>
                            </span>
                        </td>
                    </tr>
                </tbody></table>
            </div>
            <br>
            <br>
            <br>
        </p>

    <div class="container">
        <p id="sect-patents">
            <h2>Patents</h2>
            <br>
            <div class="publication">
                <strong>
                    Neural Network Training Technique
                </strong>
                <br>
                Guilin Liu, <b>Ning Yu</b>, Aysegul Dundar, Andrew Tao, Bryan Catanzaro
                <br>
                <em>US Application No. 17/165,745</em>
            </div>
            <br>
            <div class="publication">
                <strong>
                    <a href="https://patentimages.storage.googleapis.com/43/18/50/b310bb01ca1ef7/US10818043.pdf" target="_blank" rel="nofollow">Texture Interpolation Using Neural Networks</a>
                </strong>
                <br>
                Connelly Barnes, Sohrab Amirghodsi, Michal Lukáč, Eli Shechtman, <b>Ning Yu</b>
                <br>
                <em>US Patent No. 10,818,043</em>
                <br>
                <span class="links">
                    <a href="https://patentimages.storage.googleapis.com/43/18/50/b310bb01ca1ef7/US10818043.pdf" target="_blank" rel="nofollow">pdf</a>
                </span>
            </div>
            <br>
            <div class="publication">
                <strong>
                    <a href="https://patentimages.storage.googleapis.com/fb/a4/32/3d3030419f6859/US10810721.pdf" target="_blank" rel="nofollow">Digital Image Defect Identification and Correction</a>
                </strong>
                <br>
                Radomír Měch, <b>Ning Yu</b>, Xiaohui Shen, Zhe Lin
                <br>
                <em>US Patent No. 10,810,721</em>
                <br>
                <span class="links">
                    <a href="https://patentimages.storage.googleapis.com/fb/a4/32/3d3030419f6859/US10810721.pdf" target="_blank" rel="nofollow">pdf</a>
                </span>
            </div>
        </div>
    </p>

    <div class="container">
        <p id="sect-awards">
            <h2>Selected Awards</h2>
            <br>
            <div>
                [2021] <a href="https://blog.twitch.tv/en/2021/01/07/introducing-our-2021-twitch-research-fellows/" target="_blank" rel="nofollow">Twitch (Amazon) Research Fellowship</a>
                <br>
                [2020] <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/finalists" target="_blank" rel="nofollow">Qualcomm Innovation Fellowship Finalist</a>
                <br>
                [2019] <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/finalists" target="_blank" rel="nofollow">Qualcomm Innovation Fellowship Finalist</a>
                <br>
                [2015] <a href="http://spie.org/about-spie/press-room/mi15-news" target="_blank" rel="nofollow">SPIE Best Student Paper Finalist</a>
                <br>
                [2015] <a href="http://spie.org/about-spie/press-room/mi15-news" target="_blank" rel="nofollow">SPIE Travel Scholarship</a>
                <br>
                [2012] Chinese National Fellowship
                <br>
                [2012] Microsoft Young Fellowship
                <br>
                [2012] Meritorious Winner of the Mathematical Contest in Modeling
                <br>
                [2011] 2nd Prize of the Chinese Mathematical Contest in Modeling
            </div>
        </div>
    </p>

    <div class="container">
        <p id="sect-mentoring">
            <h2>Mentoring</h2>
            <br>
            <div>
                <a href="https://eml-unitue.de/people/shyamgopal-karthik" target="_blank" rel="nofollow">Shyamgopal Karthik</a> @MPI-IS
                <br>
                <a href="" target="_blank" rel="nofollow">Zeyang Sha</a> @CISPA
                <br>
                <a href="https://yvonnemamama.github.io/" target="_blank" rel="nofollow">Yihan Ma</a> @CISPA
                <br>
                <a href="https://praeclarumjj3.github.io/" target="_blank" rel="nofollow">Jitesh Jain</a> @IIT
                <br>
                <a href="https://zhenglisec.github.io/" target="_blank" rel="nofollow">Zheng Li</a> @CISPA
                <br>
                <a href="https://liu.ai/" target="_blank" rel="nofollow">Yugeng Liu</a> @CISPA
                <br>
                <a href="https://www.linkedin.com/in/vladislav-skripniuk-8a8891143/?originalSubdomain=ru" target="_blank" rel="nofollow">Vladislav Skripniuk</a> @Audatic
                <br>
                <a href="https://a514514772.github.io/#publications" target="_blank" rel="nofollow">Hui-Po Wang</a> @CISPA
                <br>
                <a href="https://cispa.de/en/people/dingfan.chen" target="_blank" rel="nofollow">Dingfan Chen</a> @CISPA
                <br>
                <a href="https://dynamo.cs.ucsb.edu/people/sharma" target="_blank" rel="nofollow">Saurabh Sharma</a> @UCSB
            </div>
        </div>
    </p>

    <div class="container">
        <p id="sect-reviewing">
            <h2>Reviewing</h2>
            <br>
            <div>
                CVPR 2020,2021,2022
                <br>
                ICCV 2019,2021
                <br>
                ECCV 2020
                <br>
                NeurIPS 2021
                <br>
                ICML 2021
                <br>
                ICLR 2022
                <br>
                SIGGRAPH 2021
                <br>
                Eurographics 2020
                <br>
                AAAI 2020,2021,2022
                <br>
                IJCAI 2020
                <br>
                ICRA 2020
                <br>
                TPAMI
                <br>
                IJCV
                <br>
                TOG
                <br>
                Neurocomputing
                <br>
                PR Letters
                <br>
                TVCJ
            </div>
        </div>
    </p>

    <div class="container">
        <p id="sect-teaching">
            <h2>Teaching</h2>
            <br>
            <div>
                @<b>University of Virginia</b>
                <br>
                Computer Graphics
                <br>
                Operating Systems
                <br>
                Information Technology
                <br>
                <br>
                @<b>University of Pennsylvania</b>
                <br>
                Probability Theory
            </div>
        </div>
    </p>

</body></html>
