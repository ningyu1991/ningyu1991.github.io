<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="keywords" content="Ning Yu; 于宁; Computer Vision; Visual Security; Deep Generative Modeling; University of Maryland; UMD; Max Planck Institute for Informatics; MPI-INF">
<link rel="author" href="https://ningyu1991.github.io/">

<title>Ning Yu's Homepage</title>

<style>
@media screen and (max-device-width: 480px){
  body{
    -webkit-text-size-adjust: none;
  }
}
p { font-size : 16px; }
h1 { font-size : 34px; margin : 0; padding : 0; }
h2 { font-size : 20px; margin : 0; padding : 0; }
h3 { font-size : 18px; margin : 8; padding : 0; }
body { padding : 0; font-family : Arial; font-size : 16px; background-color : #fff; }
.title { width : 700px; margin : 20px auto; }
.container { width : 900px; margin : 20px auto; border-radius: 10px;  background-color : #fff; padding : 20px;  clear:both;}
#bio {
    padding-top : 30px;
}
#me { border : 0 solid black; margin-bottom : 50px; border-radius : 10px; }
#sidebar { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0;}
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
.publogo { width: 100 px; margin-right : 20px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 5px;}
.publication strong a { color : #0000A0; }
.publication .links a { margin-right : 20px; }
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
.external a { margin : 0 10px; }
.external a.first { margin : 0 10px 0 0; }
</style>

<script async="" src="./homepage_files/analytics.js"></script>
</head>

<body>
    <div class="title">
        <div id="sidebar"><img src="./homepage_files/me.jpg" vspace="50 px" width="270 px" id="me" itemprop="photo"></div>
        <div id="bio">

            <br>

            <h1>
                <span itemprop="name">Ning Yu <font size="5">于宁</font> </span>
            </h1>

            <br>

            <p style="line-height:23px;">
                Ph.D. Student
                <br>
                University of Maryland (UMD)
                <br>
                Max Planck Institute for Informatics (MPI-INF)
                <br>
                <br>
                ningyu at cs.umd.edu
                <br>
                ningyu at mpi-inf.mpg.de
                <br>
                <br>
            </p>
            <p class="external">
                <a href="https://scholar.google.com/citations?user=TaJND9YAAAAJ&hl=en" class="first" target="_blank" rel="nofollow">Google Scholar</a>|
                <a href="https://github.com/ningyu1991" target="_blank" rel="nofollow">GitHub</a>|
                <a href="https://www.linkedin.com/in/ning-yu-51b31087" target="_blank" rel="nofollow">LinkedIn</a>|
                <a href="https://twitter.com/realNingYu" target="_blank" rel="nofollow">Twitter</a>
            </p>
        </div>
    </div>

    <div class="container">
        <h2>About me</h2>
        <p>
            I am a Ph.D. student in Computer Science jointly affiliated with the University of Maryland and Max Planck Institute for Informatics, under the supervision of <a href="http://legacydirs.umiacs.umd.edu/~lsd/" target="_blank" rel="nofollow">Larry Davis</a> and <a href="https://cispa.saarland/group/fritz/" target="_blank" rel="nofollow">Mario Fritz</a>.
            <br>
            <br>
            My research aspirations lie in computer vision and visual security, with a focused lens at the bright side and dark side of deep generative models. I am passionate about recreating the visual world in a responsible manner against deep fake misuse.
            <br>
            <br>
            I interned at NVIDIA Research, working with <a href="https://liuguilin1225.github.io/" target="_blank" rel="nofollow">Guilin Liu</a> and <a href="https://ctnzr.io/" target="_blank" rel="nofollow">Bryan Catanzaro</a>.
            <br>
            I interned at Adobe Research, working with <a href="http://www.connellybarnes.com/work/" target="_blank" rel="nofollow">Connelly Barnes</a>, <a href="https://research.adobe.com/person/eli-shechtman/" target="_blank" rel="nofollow">Eli Shechtman</a>, <a href="https://xiaohuishen.github.io/" target="_blank" rel="nofollow">Xiaohui Shen</a>, and <a href="https://sites.google.com/site/zhelin625/" target="_blank" rel="nofollow">Zhe Lin</a>.
            <br>
            <br>
            My selected works include <a href="https://github.com/ningyu1991/ScalableGANFingerprints" target="_blank" rel="nofollow">Scalable GAN Fingerprints</a>, <a href="https://github.com/ningyu1991/ArtificialGANFingerprints" target="_blank" rel="nofollow">Artificial GAN Fingerprints</a>, <a href="./projects/GANFingerprints.html" target="_blank" rel="nofollow">GAN Fingerprints</a>, <a href="./projects/InclusiveGAN.html" target="_blank" rel="nofollow">Inclusive GAN</a>, <a href="./projects/TextureMixer.html" target="_blank" rel="nofollow">Texture Mixer</a>, and <a href="./projects/DefectDetection.html" target="_blank" rel="nofollow">Defect Detection</a>.
            <br>
            <br>
            My research was featured in media press such as thejiangmen and QbitAI.
            <br>
            <br>
            I am a recipient of <a href="https://blog.twitch.tv/en/2021/01/07/introducing-our-2021-twitch-research-fellows/" target="_blank" rel="nofollow">Twitch (Amazon) Research Fellowship</a>, Microsoft Young Fellowship, <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/finalists" target="_blank" rel="nofollow">Qualcomm Innovation Fellowship Finalist</a>, and <a href="http://spie.org/about-spie/press-room/mi15-news" target="_blank" rel="nofollow">SPIE Best Student Paper Finalist</a>.
        </p>
    </div>

    <div class="container">
        <h2>News</h2>
        <p>
            [02/2021] Our work on <a href="https://arxiv.org/pdf/2011.14107.pdf" target="_blank" rel="nofollow">Hijack-GAN</a> is accepted to CVPR 2021.
            <br>
            [02/2021] Our work on <a href="" target="_blank" rel="nofollow">ML-Based Food Nutrient Prediction</a> is accepted to Journal of Food Composition and Analysis.
            <br>
            [01/2021] Our code for <a href="https://github.com/ningyu1991/InclusiveGAN" target="_blank" rel="nofollow">Inclusive GAN</a> is released.
            <br>
            [09/2020] Our code for <a href="https://github.com/ssfootball04/class-balanced-experts" target="_blank" rel="nofollow">Class Balanced Experts for Long-Tailed Recognition</a> is released.
            <br>
            [08/2020] Our work on <a href="https://arxiv.org/pdf/2004.03706.pdf" target="_blank" rel="nofollow">Class Balanced Experts for Long-Tailed Recognition</a> is accepted to GCPR 2020.
            <br>
            [08/2020] Our code for <a href="https://github.com/DingfanChen/GAN-Leaks" target="_blank" rel="nofollow">GAN-Leaks</a> is released.
            <br>
            [06/2020] Our work on <a href="https://arxiv.org/pdf/2004.03355.pdf" target="_blank" rel="nofollow">Inclusive GAN</a> is accepted to ECCV 2020.
            <br>
            [03/2020] Our work on <a href="https://arxiv.org/pdf/1909.03935.pdf" target="_blank" rel="nofollow">GAN-Leaks</a> is accepted to CCS 2020.
        </p>
    </div>

    <div class="container">
        <h2>Publications</h2>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_AttentionContrastGAN.png" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="" target="_blank" rel="nofollow">GANs with Attention and Contrastive Learning</a>
                        </strong>
                        <br>
                        <br>
                        <b>Ning Yu</b>, Guilin Liu, Aysegul Dundar, Andrew Tao, Bryan Catanzaro, Larry Davis, Mario Fritz
                        <br>
                        <br>
                        <em>arXiv 2021</em>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_ScalableGANFingerprints.png" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="https://arxiv.org/pdf/2012.08726" target="_blank" rel="nofollow">Responsible Disclosure of Generative Models Using Scalable Fingerprinting</a>
                        </strong>
                        <br>
                        <br>
                        <b>Ning Yu</b>*, Vladislav Skripniuk*, Dingfan Chen, Larry Davis, Mario Fritz
                        <br>
                        <br>
                        <em>arXiv 2021</em>
                        <br>
                        <br>
                        <span class="links">
                            <a href="https://arxiv.org/pdf/2012.08726" target="_blank" rel="nofollow">pdf</a>
                            <a href="https://github.com/ningyu1991/ScalableGANFingerprints" target="_blank" rel="nofollow">code</a>
                        </span>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_ArtificialGANFingerprints.png" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="https://arxiv.org/pdf/2007.08457.pdf" target="_blank" rel="nofollow">Artificial GAN Fingerprints: Rooting Deepfake Attribution in Training Data</a>
                        </strong>
                        <br>
                        <br>
                        <b>Ning Yu</b>*, Vladislav Skripniuk*, Sahar Abdelnabi, Mario Fritz
                        <br>
                        <br>
                        <em>arXiv 2020</em>
                        <br>
                        <br>
                        <span class="links">
                            <a href="https://arxiv.org/pdf/2007.08457.pdf" target="_blank" rel="nofollow">pdf</a>
                            <a href="https://github.com/ningyu1991/ArtificialGANFingerprints" target="_blank" rel="nofollow">code</a>
                        </span>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_HijackGAN.png" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="https://arxiv.org/pdf/2011.14107.pdf" target="_blank" rel="nofollow">Hijack-GAN: Unintended-Use of Pretrained, Black-Box GANs</a>
                        </strong>
                        <br>
                        <br>
                        Hui-Po Wang, <b>Ning Yu</b>, Mario Fritz
                        <br>
                        <br>
                        <em>CVPR 2021</em>
                        <br>
                        <br>
                        <span class="links">
                            <a href="https://arxiv.org/pdf/2011.14107.pdf" target="_blank" rel="nofollow">pdf</a>
                            <a href="https://github.com/a514514772/hijackgan" target="_blank" rel="nofollow">code</a>
                        </span>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_FoodNutrientPrediction.jpg" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="" target="_blank" rel="nofollow">Application of Machine Learning for Predicting Label Nutrients Using USDA Global Branded Food Products Database (BFPD)</a>
                        </strong>
                        <br>
                        <br>
                        Peihua Ma, An Li, <b>Ning Yu</b>, Ying Li, Rahul Bahadur, Jaspreet Ahuja, Qin Wang
                        <br>
                        <br>
                        <em>Journal of Food Composition and Analysis 2021</em>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_ClassBalancedExperts.png" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="https://arxiv.org/pdf/2004.03706.pdf" target="_blank" rel="nofollow">Long-Tailed Recognition Using Class-Balanced Experts</a>
                        </strong>
                        <br>
                        <br>
                        Saurabh Sharma, <b>Ning Yu</b>, Mario Fritz, Bernt Schiele
                        <br>
                        <br>
                        <em>GCPR 2020</em>
                        <br>
                        <br>
                        <span class="links">
                            <a href="https://arxiv.org/pdf/2004.03706.pdf" target="_blank" rel="nofollow">pdf</a>
                            <a href="https://github.com/ssfootball04/class-balanced-experts" target="_blank" rel="nofollow">code</a>
                            <a href="https://www.youtube.com/watch?v=1rxMDoIm6oM&feature=youtu.be&t=29m58s" target="_blank" rel="nofollow">video</a>
                        </span>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_GANLeaks.png" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="https://arxiv.org/pdf/1909.03935.pdf" target="_blank" rel="nofollow">GAN-Leaks: A Taxonomy of Membership Inference Attacks against GANs</a>
                        </strong>
                        <br>
                        <br>
                        Dingfan Chen, <b>Ning Yu</b>, Yang Zhang, Mario Fritz
                        <br>
                        <br>
                        <em>CCS 2020</em>
                        <br>
                        <br>
                        <span class="links">
                            <a href="https://arxiv.org/pdf/1909.03935.pdf" target="_blank" rel="nofollow">pdf</a>
                            <a href="https://github.com/DingfanChen/GAN-Leaks" target="_blank" rel="nofollow">code</a>
                            <a href="./homepage_files/poster_GANLeaks.pdf" target="_blank" rel="nofollow">poster</a>
                            <a href="https://www.youtube.com/watch?v=UkOe_sGRYec" target="_blank" rel="nofollow">video (short)</a>
                            <a href="https://www.youtube.com/watch?v=APnsV8AFXZQ" target="_blank" rel="nofollow">video (full)</a>
                        </span>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_InclusiveGAN.png" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="./projects/InclusiveGAN.html" target="_blank" rel="nofollow">Inclusive GAN: Improving Data and Minority Coverage in Generative Models</a>
                        </strong>
                        <br>
                        <br>
                        <b>Ning Yu</b>, Ke Li, Peng Zhou, Jitendra Malik, Larry Davis, Mario Fritz
                        <br>
                        <br>
                        <em>ECCV 2020</em>
                        <br>
                        <br>
                        <span class="links">
                            <a href="https://arxiv.org/pdf/2004.03355.pdf" target="_blank" rel="nofollow">pdf</a>
                            <a href="./projects/InclusiveGAN.html" target="_blank" rel="nofollow">project</a>
                            <a href="https://github.com/ningyu1991/InclusiveGAN" target="_blank" rel="nofollow">code</a>
                            <a href="https://www.youtube.com/watch?v=JbHWuLsn_zg" target="_blank" rel="nofollow">video (short)</a>
                            <a href="https://www.youtube.com/watch?v=oCb4cpsQ7do" target="_blank" rel="nofollow">video (full)</a>
                            <a href="https://mp.weixin.qq.com/s/6CCWQY8d0NoHEuMqWEp2dw" target="_blank" rel="nofollow">press</a>
                        </span>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_GANFingerprints.png" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="./projects/GANFingerprints.html" target="_blank" rel="nofollow">Attributing Fake Images to GANs: Learning and Analyzing GAN Fingerprints</a>
                        </strong>
                        <br>
                        <br>
                        <b>Ning Yu</b>, Larry Davis, Mario Fritz
                        <br>
                        <br>
                        <em>ICCV 2019</em>
                        <br>
                        <br>
                        <span class="links">
                            <a href="https://arxiv.org/pdf/1811.08180.pdf" target="_blank" rel="nofollow">pdf</a>
                            <a href="./projects/GANFingerprints.html" target="_blank" rel="nofollow">project</a>
                            <a href="https://github.com/ningyu1991/GANFingerprints" target="_blank" rel="nofollow">code</a>
                            <a href="./homepage_files/poster_GANFingerprints.pdf" target="_blank" rel="nofollow">poster</a>
                            <a href="https://mp.weixin.qq.com/s/se1ZyR_gfzliWB5X72OZ1Q" target="_blank" rel="nofollow">press</a>
                        </span>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_TextureMixer.png" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="./projects/TextureMixer.html" target="_blank" rel="nofollow">Texture Mixer: A Network for Controllable Synthesis and Interpolation of Texture</a>
                        </strong>
                        <br>
                        <br>
                        <b>Ning Yu</b>, Connelly Barnes, Eli Shechtman, Sohrab Amirghodsi, Michal Lukáč
                        <br>
                        <br>
                        <em>CVPR 2019</em>
                        <br>
                        <br>
                        <span class="links">
                            <a href="https://arxiv.org/pdf/1901.03447.pdf" target="_blank" rel="nofollow">pdf</a>
                            <a href="./projects/TextureMixer.html" target="_blank" rel="nofollow">project</a>
                            <a href="https://github.com/ningyu1991/TextureMixer" target="_blank" rel="nofollow">code</a>
                            <a href="./homepage_files/poster_TextureMixer.pdf" target="_blank" rel="nofollow">poster</a>
                            <a href="https://mp.weixin.qq.com/s/b_gIB_zpUCcf2a8ImKMXRA" target="_blank" rel="nofollow">press</a>
                        </span>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_DefectDetection.jpg" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="./projects/DefectDetection.html" target="_blank" rel="nofollow">Learning to Detect Multiple Photographic Defects</a>
                        </strong>
                        <br>
                        <br>
                        <b>Ning Yu</b>, Xiaohui Shen, Zhe Lin, Radomír Měch, Connelly Barnes
                        <br>
                        <br>
                        <em>WACV 2018</em>
                        <br>
                        <br>
                        <span class="links">
                            <a href="https://arxiv.org/pdf/1612.01635.pdf" target="_blank" rel="nofollow">pdf</a>
                            <a href="./homepage_files/supp_DefectDetection.pdf" target="_blank" rel="nofollow">supp</a>
                            <a href="./projects/DefectDetection.html" target="_blank" rel="nofollow">project</a>
                            <a href="https://github.com/ningyu1991/DefectDetection" target="_blank" rel="nofollow">code</a>
                            <a href="./homepage_files/poster_DefectDetection.pdf" target="_blank" rel="nofollow">poster</a>
                            <a href="./homepage_files/slides_DefectDetection.pptx" target="_blank" rel="nofollow">slides</a>
                        </span>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_SupervoxelMRFSeg.png" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="./projects/SupervoxelMRFSeg.html" target="_blank" rel="nofollow">Supervoxel-Based Hierarchical Markov Random Field Framework for Multi-Atlas Segmentation</a>
                        </strong>
                        <br>
                        <br>
                        <b>Ning Yu</b>, Hongzhi Wang, Paul Yushkevich
                        <br>
                        <br>
                        <em>MICCAI Workshop 2016</em>
                        <br>
                        <br>
                        <span class="links">
                            <a href="./homepage_files/paper_SupervoxelMRFSeg.pdf" target="_blank" rel="nofollow">pdf</a>
                            <a href="./projects/SupervoxelMRFSeg.html" target="_blank" rel="nofollow">project</a>
                            <a href="./homepage_files/slides_SupervoxelMRFSeg.pptx" target="_blank" rel="nofollow">slides</a>
                        </span>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_SuperpixelBreastTumorSeg.png" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="./projects/SuperpixelBreastTumorSeg.html" target="_blank" rel="nofollow">A Superpixel-Based Framework for Automatic Tumor Segmentation on Breast DCE-MRI</a>
                        </strong>
                        <br>
                        <br>
                        <b>Ning Yu</b>, Jia Wu, Susan Weinstein, Bilwaj Gaonkar, Brad Keller, Ahmed Ashraf, YunQing Jiang, Christos Davatzikos, Emily Conant, Despina Kontos
                        <br>
                        <br>
                        <em>SPIE Medical Imaging 2015 (oral, best student paper finalist)</em>
                        <br>
                        <br>
                        <span class="links">
                            <a href="./homepage_files/paper_SuperpixelBreastTumorSeg.pdf" target="_blank" rel="nofollow">pdf</a>
                            <a href="./projects/SuperpixelBreastTumorSeg.html" target="_blank" rel="nofollow">project</a>
                            <a href="./homepage_files/slides_SuperpixelBreastTumorSeg.pptx" target="_blank" rel="nofollow">slides</a>
                            <a href="http://spie.org/about-spie/press-room/mi15-news" target="_blank" rel="nofollow">press</a>
                        </span>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_QuantBreastTumorReg.png" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="./homepage_files/paper_QuantBreastTumorReg.pdf" target="_blank" rel="nofollow">Quantification of Tumor Changes during Neoadjuvant Chemotherapy with Longitudinal Breast DCE-MRI Registration</a>
                        </strong>
                        <br>
                        <br>
                        Jia Wu, Yangming Ou, Susan Weinstein, Emily Conant, <b>Ning Yu</b>, Vahid Hoshmand, Brad Keller, Ahmed Ashraf, Mark Rosen, Angela DeMichele, Christos Davatzikos,  Despina Kontos
                        <br>
                        <br>
                        <em>SPIE Medical Imaging 2015</em>
                        <br>
                        <br>
                        <span class="links">
                            <a href="./homepage_files/paper_QuantBreastTumorReg.pdf" target="_blank" rel="nofollow">pdf</a>
、                        </span>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_BreastTumorPattern.jpg" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="./homepage_files/paper_BreastTumorPattern.pdf" target="_blank" rel="nofollow">Tumor Heterogeneity Patterns of DCE-MRI Parametric Response Maps May Augment Early Assessment of Neoadjuvant Chemotherapy: A Pilot Study of ACRIN 6657/I-SPY 1</a>
                        </strong>
                        <br>
                        <br>
                        Jia Wu, Susan Weinstein, Andrew Oustimov, Lauren Pantalone, <b>Ning Yu</b>, Yangming Ou, Mark Rosen, Angela DeMichele, Christos Davatzikos, Despina Kontos
                        <br>
                        <br>
                        <em>RSNA 2015</em>
                        <br>
                        <br>
                        <span class="links">
                            <a href="./homepage_files/paper_BreastTumorPattern.pdf" target="_blank" rel="nofollow">pdf</a>
                        </span>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_InvestigationBreatTumorReg.png" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="./homepage_files/paper_InvestigationBreatTumorReg.pdf" target="_blank" rel="nofollow">A Feasibility Study Investigating the Use of Quantitative Measures of Spatio-Temporal Tumor Heterogeneity Derived from 4D Breast DCE-MRI Registration as a Biomarker of Response to Neoadjuvant Chemotherapy</a>
                        </strong>
                        <br>
                        <br>
                        Jia Wu, Yangming Ou, Susan Weinstein, Emily Conant, <b>Ning Yu</b>, Vahid Hoshmand, Brad Keller, Ahmed Ashraf, Mark Rosen, Angela DeMichele, Christos Davatzikos,  Despina Kontos
                        <br>
                        <br>
                        <em>ISMRM Workshop 2014</em>
                        <br>
                        <br>
                        <span class="links">
                            <a href="./homepage_files/paper_InvestigationBreatTumorReg.pdf" target="_blank" rel="nofollow">pdf</a>
                        </span>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>
        <div class="publication">
            <table><tbody>
                <tr>
                    <td>
                        <img src="./homepage_files/logo_FeaturePointCorrespondencesTracking.png" class="publogo" width="200 px">
                    </td>
                    <td>
                        <strong>
                            <a href="./projects/FeaturePointCorrespondencesTracking.html" target="_blank" rel="nofollow">Robust Feature Points Correspondences for Visual Object Tracking</a>
                        </strong>
                        <br>
                        <br>
                        <b>Ning Yu</b>
                        <br>
                        <br>
                        <em>Undergraduate Thesis 2013</em>
                        <br>
                        <br>
                        <span class="links">
                            <a href="./homepage_files/paper_FeaturePointCorrespondencesTracking.pdf" target="_blank" rel="nofollow">pdf</a>
                            <a href="./projects/FeaturePointCorrespondencesTracking.html" target="_blank" rel="nofollow">project</a>
                            <a href="./homepage_files/slides_FeaturePointCorrespondencesTracking.pptx" target="_blank" rel="nofollow">slides</a>
                        </span>
                    </td>
                </tr>
            </tbody></table>
        </div>
        <br>
        <br>
        <br>

    <div class="container">
        <h2>Patents</h2>
        <br>
        <div class="publication">
            <strong>
                Neural Network Training Technique
            </strong>
            <br>
            Guilin Liu, <b>Ning Yu</b>, Aysegul Dundar, Andrew Tao, Bryan Catanzaro
            <br>
            <em>US Application No. 17/165,745</em>
        </div>
        <br>
        <div class="publication">
            <strong>
                <a href="https://patentimages.storage.googleapis.com/43/18/50/b310bb01ca1ef7/US10818043.pdf" target="_blank" rel="nofollow">Texture Interpolation Using Neural Networks</a>
            </strong>
            <br>
            Connelly Barnes, Sohrab Amirghodsi, Michal Lukáč, Eli Shechtman, <b>Ning Yu</b>
            <br>
            <em>US Patent No. 10,818,043</em>
            <br>
            <span class="links">
                <a href="https://patentimages.storage.googleapis.com/43/18/50/b310bb01ca1ef7/US10818043.pdf" target="_blank" rel="nofollow">pdf</a>
            </span>
        </div>
        <br>
        <div class="publication">
            <strong>
                <a href="https://patentimages.storage.googleapis.com/fb/a4/32/3d3030419f6859/US10810721.pdf" target="_blank" rel="nofollow">Digital Image Defect Identification and Correction</a>
            </strong>
            <br>
            Radomír Měch, <b>Ning Yu</b>, Xiaohui Shen, Zhe Lin
            <br>
            <em>US Patent No. 10,810,721</em>
            <br>
            <span class="links">
                <a href="https://patentimages.storage.googleapis.com/fb/a4/32/3d3030419f6859/US10810721.pdf" target="_blank" rel="nofollow">pdf</a>
            </span>
        </div>
    </div>

    <div class="container">
        <h2>Selected Awards</h2>
        <br>
        <div>
            [2021] <a href="https://blog.twitch.tv/en/2021/01/07/introducing-our-2021-twitch-research-fellows/" target="_blank" rel="nofollow">Twitch (Amazon) Research Fellowship</a>
            <br>
            [2020] <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/finalists" target="_blank" rel="nofollow">Qualcomm Innovation Fellowship Finalist</a>
            <br>
            [2019] <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/finalists" target="_blank" rel="nofollow">Qualcomm Innovation Fellowship Finalist</a>
            <br>
            [2015] <a href="http://spie.org/about-spie/press-room/mi15-news" target="_blank" rel="nofollow">SPIE Best Student Paper Finalist</a>
            <br>
            [2015] <a href="http://spie.org/about-spie/press-room/mi15-news" target="_blank" rel="nofollow">SPIE Travel Scholarship</a>
            <br>
            [2012] Chinese National Fellowship
            <br>
            [2012] Microsoft Young Fellowship
            <br>
            [2012] Meritorious Winner of the Mathematical Contest in Modeling
            <br>
            [2011] 2nd Prize of the Chinese Mathematical Contest in Modeling
        </div>
    </div>

    <div class="container">
        <h2>Mentoring</h2>
        <br>
        <div>
            <a href="https://www.linkedin.com/in/vladislav-skripniuk-8a8891143/?originalSubdomain=ru" target="_blank" rel="nofollow">Vladislav Skripniuk</a> @Audatic
            <br>
            <a href="https://www.linkedin.com/in/hui-po-wang-7a0158137/?originalSubdomain=de" target="_blank" rel="nofollow">Hui-Po Wang</a> @CISPA
            <br>
            <a href="https://cispa.de/en/people/dingfan.chen" target="_blank" rel="nofollow">Dingfan Chen</a> @CISPA
            <br>
            <a href="https://dynamo.cs.ucsb.edu/people/sharma" target="_blank" rel="nofollow">Saurabh Sharma</a> @UCSB
        </div>
    </div>

    <div class="container">
        <h2>Invited Reviewer</h2>
        <br>
        <div>
            CVPR 2020,2021
            <br>
            ICCV 2019, 2021
            <br>
            ECCV 2020
            <br>
            ICML 2021
            <br>
            AAAI 2020,2021
            <br>
            IJCAI 2020
            <br>
            ICRA 2020
            <br>
            Eurographics 2020
            <br>
            TPAMI
            <br>
            IJCV
            <br>
            TOG
            <br>
            Neurocomputing
            <br>
            PR Letters
            <br>
            TVCJ
        </div>
    </div>

    <div class="container">
        <h2>Teaching</h2>
        <br>
        <div>
            @<b>University of Virginia</b>
            <br>
            Computer Graphics
            <br>
            Operating Systems
            <br>
            Information Technology
            <br>
            <br>
            @<b>University of Pennsylvania</b>
            <br>
            Probability Theory
        </div>
    </div>

</body></html>
